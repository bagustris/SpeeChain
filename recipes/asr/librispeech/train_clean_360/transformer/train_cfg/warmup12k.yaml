model:
  model_type: asr.EuterpeASR
  model_conf:
    required_modules:
      - encoder_prenet
      - encoder
      - decoder_prenet
      - decoder
      - decoder_postnet
    init: xavier
    frozen_modules:
    pretrained_model:
    loss_weights:
    customize_conf:
      token_dict: /ahc/work4/heli-qi/euterpe-heli-qi/datasets/speech/librispeech/data/char/train_clean_100/dict


  module_conf:
    feat_frontend:
      type: feat_frontend.speech2mel.EuterpeSpeech2MelSpec
      conf:
        sr: 16000
        preemphasis: 0.97
        n_fft: 2048
        hop_length: 0.0125
        win_length: 0.05
        n_mels: 80
        fmin: 125
        fmax: 7600

    encoder_prenet:
      type: prenet.conv2d_asr.EuterpeConv2dASRPrenet
      conf:
        feat_dim: 80
        conv_dims:
          - 64
          - 64
        conv_kernel: 3
        conv_stride: 2
        conv_batchnorm: true
        lnr_dims:
          - 256
        lnr_dropout:
          - 0.1

    encoder:
      type: transformer.encoder.EuterpeTransformerEncoder
      conf:
        posenc_type: sep
        posenc_maxlen: 5000
        posenc_dropout: 0.1
        d_model: 256
        num_heads: 4
        num_layers: 12
        att_dropout: 0.1
        fdfwd_dim: 2048
        fdfwd_dropout: 0.1
        res_dropout: 0.1
        layernorm_first: true

    decoder_prenet:
      type: prenet.embed.EuterpeEmbedPrenet
      conf:
        vocab_size: 31
        embedding_dim: 256

    decoder:
      type: transformer.decoder.EuterpeTransformerDecoder
      conf:
        posenc_type: sep
        posenc_maxlen: 5000
        posenc_dropout: 0.1
        d_model: 256
        num_heads: 4
        num_layers: 6
        att_dropout: 0.1
        fdfwd_dim: 2048
        fdfwd_dropout: 0.1
        res_dropout: 0.1
        layernorm_first: true

    decoder_postnet:
      type: postnet.token.EuterpeTokenPostnet
      conf:
        input_dim: 256
        vocab_size: 31

  criterion_conf:
    cross_entropy:
      type: cross_entropy.EuterpeCrossEntropy

    accuracy:
      type: accuracy.EuterpeAccuracy

    error_rate:
      type: error_rate.EuterpeErrorRate


optimedulers:
  noam_adam:
    type: noam.EuterpeNoamOptimeduler
    conf:
      optim_type: Adam
      optim_conf:
        betas:
          - 0.9
          - 0.98
        eps: 1.0e-9
      optim_losses: cross_entropy
      d_model: 256
      warmup_steps: 12000