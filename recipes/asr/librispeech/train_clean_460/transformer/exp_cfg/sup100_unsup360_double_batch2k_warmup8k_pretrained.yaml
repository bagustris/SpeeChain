# Experiment environment
seed: 0
ngpu: 1
gpu: 1
num_workers: 1
pin_memory: False
non_blocking: False

# gradient descent related
grad_clip: 1.0
accum_grad: 1

# Training monitoring
train_flag: True
resume: True
result_path: "/ahc/work4/heli-qi/euterpe-heli-qi/recipe/speech/librispeech/train_clean_460/asr/transformer/exp/sup100_unsup360_double_batch2k_warmup8k_pretrained"
num_epochs: 100
valid_per_epochs: 1
report_per_steps: 100
best_model_num: 5
best_model_mode: max
best_model_metric: accuracy
early_stopping_patience: 10
test_model: best

# Experiment configurations
data_cfg: "/ahc/work4/heli-qi/euterpe-heli-qi/recipe/speech/librispeech/train_clean_460/data_cfg/sup100_unsup360_double_batch2k.yaml"
train_cfg: "/ahc/work4/heli-qi/euterpe-heli-qi/recipe/speech/librispeech/train_clean_460/asr/transformer/model_cfg/semi_warmup8k_pretrained.yaml"
test_cfg: "/ahc/work4/heli-qi/euterpe-heli-qi/config/infer/beam_search/beam_size=16_maxlen_ratio=1.0.yaml"