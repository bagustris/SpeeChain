# Experiment environment
seed: 0
ngpu: 1
num_workers: 1
pin_memory: True
non_blocking: True

# gradient descent related
grad_clip: 1.0
accum_grad: 1

# Training monitoring
resume: True
result_path: "/ahc/work4/heli-qi/euterpe-heli-qi/results/asr/transformer/librispeech_500"
num_epochs: 100
valid_per_epochs: 1
report_per_steps: 100
best_model_num: 5
best_model_mode: max
best_model_metric: accuracy
early_stopping_patience: 10

# Experiment configurations
data_cfg: "/ahc/work4/heli-qi/euterpe-heli-qi/config/data/librispeech_500.yaml"
train_cfg: "/ahc/work4/heli-qi/euterpe-heli-qi/config/train/asr/transformer_warmup20k.yaml"