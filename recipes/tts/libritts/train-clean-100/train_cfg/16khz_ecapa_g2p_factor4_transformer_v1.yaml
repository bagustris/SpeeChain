### Author: Heli Qi
### Affiliation: NAIST
### Date: 2022.09


### --- Reference Values --- ###
# data-related
dataset: libritts
train_set: train-clean-100
data_root: !ref datasets/<dataset>/data

# waveform-related
wav_format: wav16000
sample_rate: 16000

# tokenizer-related
txt_format: normal
token_type: g2p
token_num: full_tokens

# model-related
reduction_factor: 4
spk_emb_dim: 192
norm_type: global

layer_num: 6
head_num: 8
d_model: 512
fdfwd_dim: 2048
dropout: 0.5
trmf_dropout: 0.1

# optimizer-related
warmup_steps: 8000
### ------------------------ ###


model:
  model_type: ar_tts.ARTTS
  model_conf:
    customize_conf:
      token_type: !ref <token_type>
      token_vocab: !ref <data_root>/<token_type>/<train_set>/<token_num>/<txt_format>/vocab
      reduction_factor: !ref <reduction_factor>
      return_att_head_num: 2
      return_att_layer_num: 2

  module_conf:
    enc_emb:
      type: emb
      conf:
        embedding_dim: !ref <d_model>

    enc_prenet:
      type: conv1d
      conf:
        conv_dims:
          - !ref <d_model>
          - !ref <d_model>
          - !ref <d_model>
        conv_kernel: 5
        conv_batchnorm: true
        lnr_dims: !ref <d_model>

    encoder:
      type: transformer
      conf:
        posenc_dropout: !ref <trmf_dropout>
        posenc_scale: true
        emb_scale: false
        emb_layernorm: true
        d_model: !ref <d_model>
        num_heads: !ref <head_num>
        num_layers: !ref <layer_num>
        att_dropout: !ref <trmf_dropout>
        fdfwd_dim: !ref <fdfwd_dim>
        fdfwd_dropout: !ref <trmf_dropout>
        res_dropout: !ref <trmf_dropout>
        layernorm_first: true

    frontend:
      type: mel_fbank
      conf:
        sr: !ref <sample_rate>
        mag_spec: True
        hop_length: 256
        win_length: 1024
        n_mels: 80
        fmin: 0
        fmax: 8000
        log_base: null
        clamp: 1e-5

    normalize:
      norm_type: !ref <norm_type>

    dec_prenet:
      type: linear
      conf:
        lnr_dims:
          - 256
          - 256
          - !ref <d_model>
        lnr_dropout: !ref <dropout>
        zero_centered: True

    spk_emb:
      spk_emb_dim: !ref <spk_emb_dim>
      spk_emb_comb: concat
      spk_emb_scale: false
      spk_emb_act: Softsign

    decoder:
      type: transformer
      conf:
        posenc_dropout: !ref <trmf_dropout>
        posenc_scale: true
        emb_scale: false
        emb_layernorm: true
        d_model: !ref <d_model>
        num_heads: !ref <head_num>
        num_layers: !ref <layer_num>
        att_dropout: !ref <trmf_dropout>
        fdfwd_dim: !ref <fdfwd_dim>
        fdfwd_dropout: !ref <trmf_dropout>
        res_dropout: !ref <trmf_dropout>
        layernorm_first: true

    dec_postnet:
      type: conv1d
      conf:
        conv_dims: !list [512, -1, -1, -1, 0]
        conv_kernel: 5
        conv_batchnorm: true
        conv_activation: Tanh
        conv_dropout: !ref <dropout>

  criterion_conf:
    feat_loss_type: L2
    stop_pos_weight: 5.0
    f_beta: 2.0
    att_guid_sigma: 0.2


optim_sches:
  type: noam.Noamlr
  conf:
    optim_type: Adam
    optim_conf:
      betas:
        - 0.9
        - 0.98
      eps: 1.0e-9
    warmup_steps: !ref <warmup_steps>